# Wyniki
print("Teoretyczne średnie:")
print(teoretical_mean)
print("Empiryczne średnie:")
print(empirical_mean)
print("Teoretyczne odchylenia standardowe:")
print(teoretical_sd)
print("Empiryczne odchylenia standardowe:")
print(empirical_sd)
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- replicate(N, wielomianowy(n, p))
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", theoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", theoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Część III i IV
## Zadanie 6
```{r, echo=FALSE}
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- replicate(N, wielomianowy(n, p))
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", theoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", theoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- replicate(N, wielomianowy(n, p))
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", theoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", theoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- replicate(N, wielomianowy(n, p))
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", theoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", theoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- wielomianowy_value(n, p, N)
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
# Funkcja generująca pojedynczą realizację rozkładu wielomianowego
wielomianowy <- function(n, p) {
k <- length(p)
proby <- sample(1:k, size = n, replace = TRUE, prob = p)
tab <- table(factor(proby, levels = 1:k))
as.vector(tab)
}
# Funkcja wykonująca N prób Monte Carlo dla rozkładu wielomianowego
wielomianowy_value <- function(n, p, N) {
k <- length(p)
W <- replicate(N, wielomianowy(n, p))  # Zamiast pętli wykorzystujemy replicate
result <- W # Średnie wartości dla każdej kategorii
return(result)
}
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- wielomianowy_value(n, p, N)
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", theoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", theoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- wielomianowy_value(n, p, N)
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", theoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", theoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- wielomianowy_value(n, p, N)
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", teoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", teoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
# Funkcja generująca pojedynczą realizację rozkładu wielomianowego
wielomianowy_sim <- function(n, p) {
k <- length(p)
proby <- sample(1:k, size = n, replace = TRUE, prob = p)
tab <- table(factor(proby, levels = 1:k))
as.vector(tab)
}
# Funkcja wykonująca N prób Monte Carlo dla rozkładu wielomianowego
wielomianowy_N_sim <- function(n, p, N) {
k <- length(p)
W <- replicate(N, wielomianowy_sim(n, p))
result <- W
return(result)
}
# Parametry symulacji
p <- c(0.5, 0.1, 0.2, 0.2)
n <- 100
N <- 10000
# Testowanie funkcji
simulated_data <- wielomianowy_N_sim(n, p, N)
# Teoretyczne wartości
teoretical_mean <- n * p
teoretical_sd <- sqrt(n * p * (1 - p))
# Empiryczne wartości
empirical_mean <- rowMeans(simulated_data)
empirical_sd <- apply(simulated_data, 1, sd)
cat("Teoretyczna średnia: ", teoretical_mean, "\n")
cat("Teoretyczne odchylenie standardowe: ", teoretical_sd, "\n")
cat("Empiryczna średnia: ", empirical_mean, "\n")
cat("Empiryczne odchylenie standardowe: ", empirical_sd, "\n")
if (!require(knitr)) install.packages("knitr")
if (!require(readr)) install.packages("readr")
if (!require(latex2exp)) install.packages("latex2exp")
if (!require(dplyr)) install.packages("dplyr")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(vctrs)) install.packages("vctrs")
if (!require(tidyr)) install.packages("tidyr")
if (!require(xtable)) install.packages("xtable")
if (!require(binom)) install.packages("binom")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "", fig.align = "center")
library(ggplot2)
# Parametry
n_values <- c(30, 100, 1000)
p_values <- seq(0.01, 1, by = 0.02)
N <- 200  # Liczba powtórzeń
alpha <- 0.05  # Poziom istotności
listan_p <- list()
listan_dlug <- list()
# Główna pętla
for (n in n_values) {
lista_pwilson <- numeric(length(p_values))
lista_pnormal <- numeric(length(p_values))
lista_pbeta <- numeric(length(p_values))
lista_dlug_wilson <- numeric(length(p_values))
lista_dlug_normal <- numeric(length(p_values))
lista_dlug_beta <- numeric(length(p_values))
for (idx in seq_along(p_values)) {
p <- p_values[idx]
perc_wilson <- 0
perc_normal <- 0
perc_beta <- 0
dlug_wilson <- 0
dlug_normal <- 0
dlug_beta <- 0
for (i in 1:N) {
X <- rbinom(1, n, p)
# Obliczanie przedziałów ufności
ci_wilson <- binom.confint(X, n, conf.level = 1 - alpha, methods = "wilson")
ci_normal <- binom.confint(X, n, conf.level = 1 - alpha, methods = "asymptotic")
ci_beta <- binom.confint(X, n, conf.level = 1 - alpha, methods = "exact")
# Sprawdzanie pokrycia przedziału
if (ci_wilson$lower <= p && ci_wilson$upper >= p) {
dlug_wilson <- dlug_wilson + (ci_wilson$upper - ci_wilson$lower)
perc_wilson <- perc_wilson + 1
}
if (ci_normal$lower <= p && ci_normal$upper >= p) {
dlug_normal <- dlug_normal + (ci_normal$upper - ci_normal$lower)
perc_normal <- perc_normal + 1
}
if (ci_beta$lower <= p && ci_beta$upper >= p) {
dlug_beta <- dlug_beta + (ci_beta$upper - ci_beta$lower)
perc_beta <- perc_beta + 1
}
}
lista_pwilson[idx] <- perc_wilson / N
lista_pnormal[idx] <- perc_normal / N
lista_pbeta[idx] <- perc_beta / N
lista_dlug_wilson[idx] <- dlug_wilson / N
lista_dlug_normal[idx] <- dlug_normal / N
lista_dlug_beta[idx] <- dlug_beta / N
}
listan_p[[as.character(n)]] <- data.frame(p_values, lista_pwilson, lista_pnormal, lista_pbeta)
listan_dlug[[as.character(n)]] <- data.frame(p_values, lista_dlug_wilson, lista_dlug_normal, lista_dlug_beta)
}
# Tworzenie wykresów
par(mfrow = c(3, 2), mar = c(5, 5, 2, 2))
methods <- c("Wilson", "Normal", "Beta")
colors <- c("blue", "red", "green")
for (i in seq_along(n_values)) {
n <- n_values[i]
# Prawdopodobieństwo pokrycia
plot(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pwilson, type = "l", col = "blue",
xlab = "p", ylab = "Prawdopodobieństwo pokrycia",
main = paste("Prawdopodobieństwo pokrycia dla n=", n),
ylim = c(min(listan_p[[as.character(n)]]$lista_pwilson), 1),  # Poprawny sposób ustawienia zakresu osi Y
cex.lab = 0.8,          # Zmniejszenie rozmiaru czcionki etykiet osi
cex.axis = 0.8)         # Zmniejszenie rozmiaru czcionki dla wartości na osiach
# Dodanie pozostałych linii
lines(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pnormal, col = "red")
lines(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pbeta, col = "green")
# Dodanie legendy
legend("bottomright", legend = methods, col = colors, lty = 1,
cex = 0.8,          # Zmniejszenie rozmiaru czcionki legendy
box.lwd = 0.5,      # Grubość obramowania legendy
inset = 0.02)
# Dodanie poziomej przerywanej linii
abline(h = 0.95, col = "black", lty = 2)
# Długość przedziału
plot(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_wilson, type = "l", col = "blue",
xlab = "p", ylab = "Średnia długość przedziału",
main = paste("Długość przedziału dla n=", n),cex.lab = 0.8)
lines(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_normal, col = "red")
lines(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_beta, col = "green")
legend("bottomright",legend = methods, col = colors, lty = 1,
cex = 0.8,          # Zmniejszenie rozmiaru czcionki
box.lwd = 0.5,      # Grubość obramowania legendy
inset = 0.02)
abline(h = 0.95, col = "black", lty = 2)
legend("bottomright", legend = methods, col = colors, lty = 1,
cex = 0.5,        # Zmniejszenie tekstu legendy
pt.cex = 0.4,     # Zmniejszenie symboli w legendzie
x.intersp = 0.1,  # Zmniejszenie odstępów poziomych
y.intersp = 0.1,  # Zmniejszenie odstępów pionowych
box.lwd = 0.1,    # Grubość obramowania legendy
inset = 0.02)     # Przesunięcie legendy do wewnątrz
}
par(mfrow = c(1, 1))
library(ggplot2)
# Parametry
n_values <- c(30, 100, 1000)
p_values <- seq(0.01, 1, by = 0.02)
N <- 200  # Liczba powtórzeń
alpha <- 0.05  # Poziom istotności
listan_p <- list()
listan_dlug <- list()
# Główna pętla
for (n in n_values) {
lista_pwilson <- numeric(length(p_values))
lista_pnormal <- numeric(length(p_values))
lista_pbeta <- numeric(length(p_values))
lista_dlug_wilson <- numeric(length(p_values))
lista_dlug_normal <- numeric(length(p_values))
lista_dlug_beta <- numeric(length(p_values))
for (idx in seq_along(p_values)) {
p <- p_values[idx]
perc_wilson <- 0
perc_normal <- 0
perc_beta <- 0
dlug_wilson <- 0
dlug_normal <- 0
dlug_beta <- 0
for (i in 1:N) {
X <- rbinom(1, n, p)
# Obliczanie przedziałów ufności
ci_wilson <- binom.confint(X, n, conf.level = 1 - alpha, methods = "wilson")
ci_normal <- binom.confint(X, n, conf.level = 1 - alpha, methods = "asymptotic")
ci_beta <- binom.confint(X, n, conf.level = 1 - alpha, methods = "exact")
# Sprawdzanie pokrycia przedziału
if (ci_wilson$lower <= p && ci_wilson$upper >= p) {
dlug_wilson <- dlug_wilson + (ci_wilson$upper - ci_wilson$lower)
perc_wilson <- perc_wilson + 1
}
if (ci_normal$lower <= p && ci_normal$upper >= p) {
dlug_normal <- dlug_normal + (ci_normal$upper - ci_normal$lower)
perc_normal <- perc_normal + 1
}
if (ci_beta$lower <= p && ci_beta$upper >= p) {
dlug_beta <- dlug_beta + (ci_beta$upper - ci_beta$lower)
perc_beta <- perc_beta + 1
}
}
lista_pwilson[idx] <- perc_wilson / N
lista_pnormal[idx] <- perc_normal / N
lista_pbeta[idx] <- perc_beta / N
lista_dlug_wilson[idx] <- dlug_wilson / N
lista_dlug_normal[idx] <- dlug_normal / N
lista_dlug_beta[idx] <- dlug_beta / N
}
listan_p[[as.character(n)]] <- data.frame(p_values, lista_pwilson, lista_pnormal, lista_pbeta)
listan_dlug[[as.character(n)]] <- data.frame(p_values, lista_dlug_wilson, lista_dlug_normal, lista_dlug_beta)
}
# Tworzenie wykresów
par(mfrow = c(3, 2), mar = c(5, 5, 2, 2))
methods <- c("Wilson", "Normal", "Beta")
colors <- c("blue", "red", "green")
for (i in seq_along(n_values)) {
n <- n_values[i]
# Prawdopodobieństwo pokrycia
plot(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pwilson, type = "l", col = "blue",
xlab = "p", ylab = "Prawdopodobieństwo pokrycia",
main = paste("Prawdopodobieństwo pokrycia dla n=", n),
ylim = c(min(listan_p[[as.character(n)]]$lista_pwilson), 1),  # Poprawny sposób ustawienia zakresu osi Y
cex.lab = 0.8,          # Zmniejszenie rozmiaru czcionki etykiet osi
cex.axis = 0.8)         # Zmniejszenie rozmiaru czcionki dla wartości na osiach
# Dodanie pozostałych linii
lines(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pnormal, col = "red")
lines(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pbeta, col = "green")
# Dodanie legendy
legend("bottomright", legend = methods, col = colors, lty = 1,
cex = 0.2,          # Zmniejszenie rozmiaru czcionki legendy
box.lwd = 0.01,      # Grubość obramowania legendy
inset = 0.02)
# Dodanie poziomej przerywanej linii
abline(h = 0.95, col = "black", lty = 2)
# Długość przedziału
plot(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_wilson, type = "l", col = "blue",
xlab = "p", ylab = "Średnia długość przedziału",
main = paste("Długość przedziału dla n=", n),cex.lab = 0.8)
lines(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_normal, col = "red")
lines(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_beta, col = "green")
legend("bottomright",legend = methods, col = colors, lty = 1,
cex = 0.2,          # Zmniejszenie rozmiaru czcionki
box.lwd = 0.01,      # Grubość obramowania legendy
inset = 0.02)
abline(h = 0.95, col = "black", lty = 2)
}
par(mfrow = c(1, 1))
library(ggplot2)
# Parametry
n_values <- c(30, 100, 1000)
p_values <- seq(0.01, 1, by = 0.02)
N <- 200  # Liczba powtórzeń
alpha <- 0.05  # Poziom istotności
listan_p <- list()
listan_dlug <- list()
# Główna pętla
for (n in n_values) {
lista_pwilson <- numeric(length(p_values))
lista_pnormal <- numeric(length(p_values))
lista_pbeta <- numeric(length(p_values))
lista_dlug_wilson <- numeric(length(p_values))
lista_dlug_normal <- numeric(length(p_values))
lista_dlug_beta <- numeric(length(p_values))
for (idx in seq_along(p_values)) {
p <- p_values[idx]
perc_wilson <- 0
perc_normal <- 0
perc_beta <- 0
dlug_wilson <- 0
dlug_normal <- 0
dlug_beta <- 0
for (i in 1:N) {
X <- rbinom(1, n, p)
# Obliczanie przedziałów ufności
ci_wilson <- binom.confint(X, n, conf.level = 1 - alpha, methods = "wilson")
ci_normal <- binom.confint(X, n, conf.level = 1 - alpha, methods = "asymptotic")
ci_beta <- binom.confint(X, n, conf.level = 1 - alpha, methods = "exact")
# Sprawdzanie pokrycia przedziału
if (ci_wilson$lower <= p && ci_wilson$upper >= p) {
dlug_wilson <- dlug_wilson + (ci_wilson$upper - ci_wilson$lower)
perc_wilson <- perc_wilson + 1
}
if (ci_normal$lower <= p && ci_normal$upper >= p) {
dlug_normal <- dlug_normal + (ci_normal$upper - ci_normal$lower)
perc_normal <- perc_normal + 1
}
if (ci_beta$lower <= p && ci_beta$upper >= p) {
dlug_beta <- dlug_beta + (ci_beta$upper - ci_beta$lower)
perc_beta <- perc_beta + 1
}
}
lista_pwilson[idx] <- perc_wilson / N
lista_pnormal[idx] <- perc_normal / N
lista_pbeta[idx] <- perc_beta / N
lista_dlug_wilson[idx] <- dlug_wilson / N
lista_dlug_normal[idx] <- dlug_normal / N
lista_dlug_beta[idx] <- dlug_beta / N
}
listan_p[[as.character(n)]] <- data.frame(p_values, lista_pwilson, lista_pnormal, lista_pbeta)
listan_dlug[[as.character(n)]] <- data.frame(p_values, lista_dlug_wilson, lista_dlug_normal, lista_dlug_beta)
}
# Tworzenie wykresów
par(mfrow = c(3, 2), mar = c(5, 5, 2, 2))
methods <- c("Wilson", "Normal", "Beta")
colors <- c("blue", "red", "green")
for (i in seq_along(n_values)) {
n <- n_values[i]
# Prawdopodobieństwo pokrycia
plot(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pwilson, type = "l", col = "blue",
xlab = "p", ylab = "Prawdopodobieństwo pokrycia",
main = paste("Prawdopodobieństwo pokrycia dla n=", n),
ylim = c(min(listan_p[[as.character(n)]]$lista_pwilson), 1),  # Poprawny sposób ustawienia zakresu osi Y
cex.lab = 0.8,          # Zmniejszenie rozmiaru czcionki etykiet osi
cex.axis = 0.8)         # Zmniejszenie rozmiaru czcionki dla wartości na osiach
# Dodanie pozostałych linii
lines(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pnormal, col = "red")
lines(listan_p[[as.character(n)]]$p_values, listan_p[[as.character(n)]]$lista_pbeta, col = "green")
# Dodanie legendy
legend("bottomright", legend = methods, col = colors, lty = 1,
cex = 0.5,          # Zmniejszenie rozmiaru czcionki legendy
box.lwd = 0.01,      # Grubość obramowania legendy
inset = 0.02)
# Dodanie poziomej przerywanej linii
abline(h = 0.95, col = "black", lty = 2)
# Długość przedziału
plot(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_wilson, type = "l", col = "blue",
xlab = "p", ylab = "Średnia długość przedziału",
main = paste("Długość przedziału dla n=", n),cex.lab = 0.8)
lines(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_normal, col = "red")
lines(listan_dlug[[as.character(n)]]$p_values, listan_dlug[[as.character(n)]]$lista_dlug_beta, col = "green")
legend("bottomright",legend = methods, col = colors, lty = 1,
cex = 0.5,          # Zmniejszenie rozmiaru czcionki
box.lwd = 0.01,      # Grubość obramowania legendy
inset = 0.02)
abline(h = 0.95, col = "black", lty = 2)
}
par(mfrow = c(1, 1))
if (!require(knitr)) install.packages("knitr")
if (!require(readr)) install.packages("readr")
if (!require(latex2exp)) install.packages("latex2exp")
if (!require(dplyr)) install.packages("dplyr")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(vctrs)) install.packages("vctrs")
if (!require(tidyr)) install.packages("tidyr")
if (!require(xtable)) install.packages("xtable")
if (!require(binom)) install.packages("binom")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "", fig.align = "center")
library(stats)
critical_test <- function(x_values, n, p0_values) {
statistic <- 0
for (i in 1:length(x_values)) {
x <- x_values[i]
p0 <- p0_values[i]
statistic <- statistic + ((x - n * p0)^2) / (n * p0)
}
p_value <- 1 - pchisq(statistic, df = length(x_values) - 1)
return(p_value)}
IW_test <- function(x_values, n, p0_values){
statistic <- 0
for (i in 1:length(x_values)) {
x <- x_values[i]
p0 <- p0_values[i]
statistic <- statistic + x*log(x/(n*p0))
}
statistic = 2*statistic
p_value <- 1 - pchisq(statistic, df = length(x_values) - 1)
return(p_value)
}
x_fisher <- matrix(c(8, 2, 1, 5), nrow = 2)
x_freeman_halton <- matrix(1:6, nrow = 2, ncol = 3)
freeman_halton_test <- fisher.test(x_freeman_halton, y = NULL, workspace = 200000, hybrid = FALSE, hybridPars = c(expect = 5, percent = 80, Emin = 1), control = list(), or = 1, alternative = "two.sided", conf.int = TRUE, conf.level = 0.95, simulate.p.value = FALSE, B = 2000)
fisher_test <- fisher.test(x_fisher, y = NULL, workspace = 200000, hybrid = FALSE, hybridPars = c(expect = 5, percent = 80, Emin = 1), control = list(), or = 1, alternative = "two.sided", conf.int = TRUE, conf.level = 0.95, simulate.p.value = FALSE, B = 2000)
freeman_halton_test
fisher_test
tabela <- table(df$PŁEĆ, df$CZY_KIER)
fisher.test(tabela)
df$CZY_ZADOW <- cut(df$PYT_2,
breaks = c(-3, 0, 2),
labels = c('NIE', 'TAK'))
