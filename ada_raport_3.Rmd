---
title: "Analiza danych ankietowych"
author:
- Weronika Jaszkiewicz
- Weronika Pyrtak
subtitle: Sprawozdanie 3
output:
  pdf_document:
    extra_dependencies: ["multirow"]
    latex_engine: xelatex
    toc: true
    fig_caption: true
    fig_width: 5
    fig_height: 4
    number_sections: false
  html_document:
    toc: true
    df_print: paged
header-includes:
  - \usepackage{booktabs}
  - \usepackage[utf8]{inputenc}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{caption}
  - \usepackage{float}
  - \captionsetup[table]{skip=10pt}
fontsize: 12pt
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
if (!require(knitr)) install.packages("knitr")
if (!require(readr)) install.packages("readr")
if (!require(latex2exp)) install.packages("latex2exp")
if (!require(dplyr)) install.packages("dplyr")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(vctrs)) install.packages("vctrs")
if (!require(tidyr)) install.packages("tidyr")
if (!require(xtable)) install.packages("xtable")
if (!require(binom)) install.packages("binom")
if (!require(energy)) install.packages("energy")
if (!require(gmodels)) install.packages("gmodels")
if (!require(DescTools)) install.packages("DescTools")
if (!require(nnet)) install.packages("nnet")


knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "", fig.align = "center")

```

\newpage

# Część I oraz II

## Zadanie 1

Funkcja *p_wartosc_warunkowy_test_symetrii()* realizuje warunkowy test
symetrii dla tabeli $2×2$. Test opiera się na liczbie niesymetrycznych
par, których suma traktowana jest jako próba w rozkładzie dwumianowym z
prawdopodobieństwem sukcesu $0.5$ (hipoteza symetrii).

P-wartość obliczana jest jako dwustronne prawdopodobieństwo uzyskania wyniku co
najmniej tak ekstremalnego jak zaobserwowany.

```{r}
p_wartosc_warunkowy_test_symetrii<- function(tabela){
  n1 <- tabela[1,2]
  n2 <- tabela[2,1]
  n <- n1 + n2
  p <- 0 
  
  if(n1 < n/2){
    for (i in 1:n1) {
    p <- p + choose(n, i) * (0.5)^i * (0.5)^(n - i)
    }
  }else if(n1 > n/2){
    for (i in n1:n) {
    p <- p + choose(n, i) * (0.5)^i * (0.5)^(n - i)
    }
  }else{
      p <- 1
  }
    return(list(p_value = p))
  }
```
\newpage
## Zadanie 2

Dane dotyączce reakcji na lek po godzinie od jego przyjęcia dla dwóch
różnych leków przeciwbólowych stosowanych w migrenie zostały
przedstawione w poniższej tabeli.

Dla tych danych przeprowadzono test
McNemara (z poprawką na ciągłość) oraz test warunkowy, miały one na celu
zweryfikowanie hipotezy, że leki są jednakowo skuczene. Przyjmowany
poziom istotności: $\alpha = 0.05$.

```{r, echo = FALSE}
library(knitr)
tabela_zad_2 <- matrix(c(1, 2, 5, 4), 
                      nrow = 2, 
                      byrow = FALSE,
                      dimnames = list(
                        c("Negatywna", "Pozytywna"), 
                        c("Negatywna", "Pozytywna")
                      ))

kable(tabela_zad_2, caption = "Reakcja na lek A vs lek B")
```

**Test McNemara z poprawka na ciagłość**

```{r, echo = FALSE}
mcnemar.test(tabela_zad_2, correct=TRUE)
```

Wynik test wskazuje na brak podstaw do odrzucenia hipotezy zerowej.
Oznacza to, że brak istotnych statystycznie różnic pomiędzy
skutecznością leku A i leku B, zatem można uznać, że leki A i B są
jednakowo skuteczne w tej próbie.

**Test warunkowy**

```{r, echo=FALSE}
p_wartosc_warunkowy_test_symetrii(tabela_zad_2)
```

P-wartość uzyskana w warunkowym teście symetrii jest znacznie większa od
poziomu istotności. Oznacza to, że nie ma podstaw do odrzucenia hipotezy
zerowej, czyli nie ma statystycznie istotnych różnic w skuteczności
między lekiem A i lekiem B.
\newpage

## Zadanie 3

W celu porównania mocy testu Z oraz testu $Z_0$ przeprowadzono symulacje
rozważając różne długości próby: $n = (50, 100, 200, 500)$.

```{r, echo = FALSE}
test_z <- function(tabela_n){
  n <-  sum(tabela_n)
  tabela_p <- tabela_n / n
  p_1sum <- sum(tabela_p[1,])
  p_sum1 <- sum(tabela_p[,1])
  D <- (tabela_n[1,2]-tabela_n[2,1])/n
  sigma_k <- (p_1sum * (1-p_1sum) + p_sum1 * (1-p_sum1) - 2*(tabela_p[1,1] * tabela_p[2,2] - tabela_p[1,2] * tabela_p[2,1]))/n
  z <- D/sqrt(sigma_k)
  p_value <- 2 * (1-pnorm(abs(z)))
  
  return(p_value)
}

test_Z0 <- function(tabela){
  n12 <- tabela[1,2]
  n21 <- tabela[2,1]
  
  z0 <- (n12 - n21)/sqrt(n12 + n21)
  p_value <- 2*(1 - pnorm(abs(z0)))
  return(p_value)
}
```

```{r, echo = FALSE}
generate_table <- function(n, p12, p21) {
  n12 <- rbinom(1, n, p12)
  n21 <- rbinom(1, n, p21)
  n11 <- floor((n - n12 - n21) / 2)
  n22 <- n - n12 - n21 - n11
  tabela <- matrix(c(n11, n12, n21, n22), nrow = 2, byrow = TRUE)
  return(tabela)
}
```

```{r, echo = FALSE}
power_sim_test <- function(n, p12, p21, test, alpha = 0.05, B = 10000) {
  rej <- 0  
  
  for(i in 1:B) {
    tabela <- generate_table(n, p12, p21)
    p_val <- test(tabela)
    if(p_val < alpha) rej <- rej + 1 
  }
  
  power <- rej / B
  return(power)
}
```

```{r, echo = FALSE}
alpha <- 0.05
B <- 1000
p21 <- 0.5
p12_values <- seq(0, 1, by = 0.05)
n_values <- c(50, 100, 200, 500)  # różne rozmiary próby
```

```{r, echo = FALSE}
results <- data.frame()

for(n in n_values) {
  for(p12 in p12_values) {
    power <- power_sim_test(n, p12, p21, test_z, alpha, B)
    results <- rbind(results, data.frame(n = n, p12 = p12, power = power))
  }
}

# Kolory do wykresu
cols <- c("red", "blue", "green3", "purple")

par(mar = c(5, 4, 4, 8), xpd = TRUE)

# Rysujemy pusty wykres z zakresami i opisami
plot(NULL, xlim = c(0,1), ylim = c(0,1),
     xlab = expression(p[1]),
     ylab = "Moc testu (power)",
     main = expression("Moc testu Z dla różnych n"))

# Rysujemy linie dla różnych n
for(i in seq_along(n_values)) {
  subset_data <- subset(results, n == n_values[i])
  lines(subset_data$p12, subset_data$power, col = cols[i], lwd = 2)
}

par(xpd = FALSE)

# Dodajemy przerywane linie pomocnicze
abline(h = 0.05, lty = 2, col = "darkgray")  # linia pozioma
abline(v = 0.5, lty = 2, col = "darkgray")   # linia pionowa

par(xpd = TRUE)

# Dodajemy legendę
legend("topright", inset = c(-0.25, 0), 
       legend = paste("n =", n_values),
       col = cols, lwd = 2, bty = "n")
```

Na wykresie przedstawiono estymowaną moc testu $Z$ przy hipotezie
zerowej $H_0: p_1 = 0.5$. Krzywe mocy są symetryczne względem wartości
$p_1 = 0.5$, co potwierdza, że test działa zgodnie z założeniem
testowania dwustronnego.

Moc testu$Z$ wzrasta wraz z oddalaniem się wartości $p_1 = 0.5$. Oznacza
to, że im większe jest rzeczywiste odchylenie od hipotezy zerowej, tym
większa jest szansa na jej odrzucenie.

Z wykresu wynika również, że test $Z$ staje się bardziej czuły wraz ze
wzrostem liczności próby. Dla większych wartości moc testu szybciej
rośnie i osiąga wartości bliskie 1. To wskazuje, że test jest bardziej
skuteczny przy większych próbach.

```{r, echo=FALSE}
results <- data.frame()

for(n in n_values) {
  for(p12 in p12_values) {
    power <- power_sim_test(n, p12, p21, test_Z0, alpha, B)
    results <- rbind(results, data.frame(n = n, p12 = p12, power = power))
  }
}

# Kolory do wykresu
cols <- c("red", "blue", "green3", "purple")

par(mar = c(5, 4, 4, 8), xpd = TRUE)

# Rysujemy pusty wykres z zakresami i opisami
plot(NULL, xlim = c(0,1), ylim = c(0,1),
     xlab = expression(p[1]),
     ylab = "Moc testu (power)",
     main = expression("Moc testu " * Z[0] * " dla różnych n"))

# Rysujemy linie dla różnych n
for(i in seq_along(n_values)) {
  subset_data <- subset(results, n == n_values[i])
  lines(subset_data$p12, subset_data$power, col = cols[i], lwd = 2)
}

par(xpd = FALSE)

# Dodajemy przerywane linie pomocnicze
abline(h = 0.05, lty = 2, col = "darkgray")  # linia pozioma
abline(v = 0.5, lty = 2, col = "darkgray")   # linia pionowa

par(xpd = TRUE)

# Dodajemy legendę
legend("topright", inset = c(-0.25, 0), 
       legend = paste("n =", n_values),
       col = cols, lwd = 2, bty = "n")
```

Na wykresie przedstawiono estymowaną moc testu $Z_0$ przy hipotezie
zerowej $H_0: p_1 = 0.5$. Widać wyraźną symetrię względem $p_1 = 0.5$,
co jets zgodne z założeniem testowania dwustronnego.

Można zauważyć, że moc testu rośnie wraz z oddalaniem się od od
$p_1 = 0.5$. – im większa różnica między wartością rzeczywistą a
wartością podaną w hipotezie zerowej, tym większa szansa na jej
odrzucenie.

Dodatkowo, dla większych prób test $Z_0$ jest bardziej czuły – moc
rośnie szybciej i szybciej zbliża się do wartości 1. Oznacza to, że test
łatwiej wykrywa niewielkie różnice przy większej liczbie obserwacji.

Na podstawie symulacji stwierdzono, że testy $Z$ i $Z_0$​ wykazują bardzo
podobne właściwości – moc obu testów rośnie wraz z licznością próby oraz
oddalaniem się $p_1 = 0.5$. Oba testy są symetryczne względem
$p_1 = 0.5$ , co jest zgodne z założeniem testowania dwustronnego. Nie
zaobserwowano istotnych różnic w mocy między testami, co sugeruje, że w
analizowanych warunkach są równoważne pod względem skuteczności.

\newpage

## Zadanie 4

Celem badania było zweryfikowanie hipotezy, że zadowolenie ze szkoleń w
pierwszym badanym okresie i w drugim badanym okresie pierwszego badania
odpowiada modelowi symetrii.

```{r, echo =FALSE}
df <- read.csv("ankieta.csv", sep = ";", fileEncoding = "Latin2")

df$CZY_ZADOW <- cut(df$PYT_2, breaks = c(-3, 0, 2),
                    labels = c('NIE', 'TAK'))

df$CZY_ZADOW_2 <- cut(df$PYT_3, breaks = c(-3, 0, 2),
                      labels = c("NIE", "TAK"),
                      include.lowest = TRUE)

tabela_czy_zadow <- table(df$CZY_ZADOW, df$CZY_ZADOW_2)
dimnames(tabela_czy_zadow) <- list(
  "Zadowolony (pomiar 1)" = levels(df$CZY_ZADOW),
  "Zadowolony (pomiar 2)" = levels(df$CZY_ZADOW_2)
)
kable(tabela_czy_zadow, 
      caption = "Tabela zadowolenia: pomiar 1 vs pomiar 2",
      row.names = TRUE)

mcnemar.test(tabela_czy_zadow, correct=TRUE)

```

Na podstawie wyniku testu McNemara (z poprawka na ciagłość) odrzucamy
hipotezę zerową ($p-value = 0.03764 < \alpha = 0.05$). Zatem możemy
stwierdzić, że poziom zadowolenia ze szkoleń uległ istotnej
statystycznie zmianie między pierwszym a drugim okresem badania.

## Zadanie 5

Na podstawie danych przedstawionych w poniższej tableli sprawdzono, czy
odpowiedzi w pierwszym badanym okresie i w drugim okresie odpowiadają
modelowi symetrii. W tym celu przeprowadzono dwa testy:

```{r, echo=FALSE}
tabela <- matrix(c(
  10, 2, 1, 1, 0,
  0, 15, 1, 1, 0,
  1, 1, 32, 6, 0,
  0, 0, 1, 96, 3,
  1, 1, 0, 1, 26
), nrow = 5, byrow = TRUE)

rownames(tabela) <- c("-2", "-1", "0", "1", "2")
colnames(tabela) <- c("-2", "-1", "0", "1", "2")

kable(tabela, caption = "Tabela reakcji", 
      align = "c")
```

**Test Bowkera**

```{r, echo = FALSE}
test_bowker <- mcnemar.test(tabela)
test_bowker
```

Wynik testu Bowkera daje spodziewany wynik $p-value = NA$. Jest on
spowodowany tym, że w liczniku statystyki testowej obliczamy
$n_{ij} + n_{ji}$, co powoduje dzielenie przez 0.

**Test IW**

```{r,echo = FALSE}

test_IW <- function(tabela){
  I <- nrow(tabela)
  n <- sum(tabela)
  G2 <- 0
  for (i in 1:I){
    for(j in 1: I){
      n_ij <- tabela[i,j]
      n_ji <- tabela[j,i]
      p_ij_est <- (n_ij + n_ji)/(2 * n)
      if(n_ij == 0){
        G2 <- G2 + 0
      }
      else{
      G2 <- G2 + n_ij * log(n_ij/(n*p_ij_est))
    }}
  }
  G2 <- 2*G2
  r <- I*(I-1)/2
  p_value <- 1 - pchisq(G2, r)
  
  return(list(statistic = G2, p_value = p_value))
}

test_IW(tabela)
```

W teście IW p-wartość przekracza standardowy poziom istotności
($\alpha = 0.05$), co zonacza, że nie ma podstaw do odrzucenia hipotezy
zerowej.Zatem test IW również nie wykazuje istotnych różnic między
ocenami podejścia firmy w dwóch okresach.

W związku z tym, także na podstawie tego testu można stwierdzić, że
ocena podejścia firmy do umożliwiania wdrażania wiedzy nie uległa
istotnej zmianie.

\newpage


# Część III


## Zadanie 6

W pewnym badaniu porównywano skuteczność dwóch metod leczenia: Leczenie A
 to nowa procedura, a Leczenie B to stara procedura.
 
 Przeanalizowano wyniki dla całej grupy pacjentów oraz wyniki w podgrupach ze względu
 na dodatkową zmienną i odpowiedziono na pytanie, czy dla danych występuje paradoks Simpsona.


```{r df,echo=FALSE, results='hide'}

#dane
all <- matrix(c(117, 104, 177, 44), nrow = 2, byrow = TRUE)
colnames(all) <- c("Poprawa", "Brak")
rownames(all) <- c("Leczenie_A", "Leczenie_B")

#dane podgrupy
with_comorbidities <- matrix(c(17, 101, 2, 36), nrow = 2, byrow = TRUE)
colnames(with_comorbidities) <- c("Poprawa", "Brak")
rownames(with_comorbidities) <- c("Leczenie_A", "Leczenie_B")

#dane podgrupy
without_comorbidities <- matrix(c(100, 3, 175, 8), nrow = 2, byrow = TRUE)
colnames(without_comorbidities) <- c("Poprawa", "Brak")
rownames(without_comorbidities) <- c("Leczenie_A", "Leczenie_B")

effectiveness <- function(data) {
  prop <- data[, "Poprawa"] / rowSums(data)
  return(round(prop, 3))
}


eff_all <- effectiveness(all)
eff_with_com <- effectiveness(with_comorbidities)
eff_without_com <- effectiveness(without_comorbidities)

cat("Skuteczność - cała grupa:\n")
print(eff_all)
cat("\nSkuteczność - z chorobami współistniejącymi:\n")
print(eff_with_com)
cat("\nSkuteczność - bez chorób współistniejących:\n")
print(eff_without_com)



```

```{r, echo=FALSE,results='hide'}

all <- matrix(c(117, 104, 177, 44), nrow = 2, byrow = TRUE,
              dimnames = list(c("Leczenie A", "Leczenie B"), c("Poprawa", "Brak")))

with_comorb <- matrix(c(17, 101, 2, 36), nrow = 2, byrow = TRUE,
                      dimnames = list(c("Leczenie A", "Leczenie B"), c("Poprawa", "Brak")))

without_comorb <- matrix(c(100, 3, 175, 8), nrow = 2, byrow = TRUE,
                         dimnames = list(c("Leczenie A", "Leczenie B"), c("Poprawa", "Brak")))


effectiveness <- function(data) {
  round(data[, "Poprawa"] / rowSums(data), 3)
}


eff_all <- effectiveness(all)
eff_with <- effectiveness(with_comorb)
eff_without <- effectiveness(without_comorb)

eff_all
eff_with
eff_without
```

```{r,echo=FALSE,results='hide'}

test_all <- chisq.test(all)
test_with <- chisq.test(with_comorb)
test_without <- chisq.test(without_comorb)

test_results <- data.frame(
  Tabela = c("Cała grupa", "Z chorobami", "Bez chorób"),
  Chi2 = round(c(test_all$statistic, test_with$statistic, test_without$statistic), 2),
  DF = c(test_all$parameter, test_with$parameter, test_without$parameter),
  p_value = round(c(test_all$p.value, test_with$p.value, test_without$p.value), 4)
)

test_results

```

\subsection*{Analiza skuteczności metod leczenia}

Dla całej grupy pacjentów skuteczność leczenia wynosi:
\[
\begin{aligned}
\text{Leczenie A:} & \quad \frac{117}{117 + 104} \approx 0{,}529 \\
\text{Leczenie B:} & \quad \frac{177}{177 + 44} \approx 0{,}801 \\
\end{aligned}
\]

Dla pacjentów z chorobami współistniejącymi:
\[
\begin{aligned}
\text{Leczenie A:} & \quad \frac{17}{17 + 101} \approx 0{,}144 \\
\text{Leczenie B:} & \quad \frac{2}{2 + 36} \approx 0{,}053 \\
\end{aligned}
\]

Dla pacjentów bez chorób współistniejących:
\[
\begin{aligned}
\text{Leczenie A:} & \quad \frac{100}{100 + 3} \approx 0{,}971 \\
\text{Leczenie B:} & \quad \frac{175}{175 + 8} \approx 0{,}956 \\
\end{aligned}
\]

\subsection*{Wniosek}

\begin{table}[H]
\centering
\begin{tabular}{lrrr}
\toprule
Tabela & Statystyka \( \chi^2 \) & DF & \textit{p}-value \\
\midrule
Cała grupa         & 47.06 & 1 & <0.0001 \\
Z chorobami        & 1.19  & 1 & 0.2755  \\
Bez chorób         & 0.18  & 1 & 0.6699  \\
\bottomrule
\end{tabular}
\caption{Wyniki testów \( \chi^2 \) niezależności dla skuteczności leczenia}
\end{table}

W każdej podgrupie leczenie A okazuje się skuteczniejsze niż leczenie B. Jednakże w całej populacji obserwujemy odwrotny wniosek — leczenie B ma wyższą skuteczność. 

Jest to klasyczny przykład paradoksu Simpsona, w którym agregacja danych zaciemnia rzeczywiste zależności występujące w podgrupach.

Dla całej grupy różnica skuteczności między Leczeniem A i B jest statystycznie istotna ($p < 0.0001$).

W podgrupach nie ma podstaw do odrzucenia hipotezy niezależności – brak istotnych różnic w skuteczności między metodami.
To potwierdza występowanie paradoksu Simpsona – agregacja danych prowadzi do innych wniosków niż analiza w podgrupach.

## Zadanie 7
Dla danych z listy 1, przyjmując za zmienną 1 - zmienną CZY_KIER, za zmienną 2 – zmienną PYT_2 i za zmienną 3 – zmienną STAZ, przedstawiono interpretacje nastepujacych modeli log-liniowych: $[1 \: 3], [13], [1 \: 2 \: 3], [12 \: 3], [12 \: 13]$ oraz $[1 \: 23]$.


```{r, echo=FALSE,results='hide'}
library(MASS)
dane <- read.csv("ankieta.csv", sep = ";", fileEncoding = "Latin2")
colnames(dane) <- c('DZIAŁ','STAZ','CZY_KIER', 'PYT_1', 'PYT_2', 'PYT_3', 'PLEC', 'WIEK')

#tabela kontyngencji
tablica <- xtabs(~ CZY_KIER + PYT_2 + STAZ, data = dane)


model_names <- c("[1 3]", "[13]", "[1 2 3]", "[12 3]", "[12 13]", "[1 23]")
formulas <- list(
  ~ CZY_KIER + STAZ,
  ~ CZY_KIER + STAZ + CZY_KIER:STAZ,
  ~ CZY_KIER * PYT_2 * STAZ,
  ~ CZY_KIER * PYT_2 + STAZ,
  ~ CZY_KIER * PYT_2 + CZY_KIER * STAZ,
  ~ CZY_KIER + PYT_2 * STAZ + CZY_KIER:STAZ
)

results <- data.frame(Model = model_names, Deviance = NA, DF = NA, p_value = NA)

for (i in seq_along(formulas)) {
  fit <- loglm(formulas[[i]], data = tablica)
  results$Deviance[i] <- round(fit$deviance, 2)
  results$DF[i] <- fit$df
  results$p_value[i] <- round(pchisq(fit$deviance, df = fit$df, lower.tail = FALSE), 4)
}

results




```

\begin{table}[H]
\centering
\begin{tabular}{lrrr}
\toprule
Model & Deviance & DF & \textit{p}-value \\
\midrule
{[1 3]}     & 203.07 & 20 & 0.0000 \\
{[13]}      & 183.98 & 18 & 0.0000 \\
{[1 2 3]}   &   0.00 &  0 & 1.0000 \\
{[12 3]}    &  33.91 & 14 & 0.0021 \\
{[12 13]}   &  14.82 & 12 & 0.2512 \\
{[1 23]}    &   4.88 &  9 & 0.8446 \\
\bottomrule
\end{tabular}
\caption{Dopasowanie modeli log-liniowych: wartość statystyki deviance, liczba stopni swobody i wartość \textit{p}.}
\end{table}


Na podstawie analizy modeli log-liniowych można stwierdzić, że najlepszym dopasowaniem do danych charakteryzuje się model $[1 \: 23]$, który uwzględnia zależność pomiędzy zmiennymi PYT_2 i STAZ oraz ich wspólny wpływ na CZY_KIER. 

Model ten ma wysoką wartość p-value ($0,8446$), co oznacza brak podstaw do jego odrzucenia, a jednocześnie jest prostszy niż model pełny $[1 \: 2 \: 3]$. Modele $[1 \: 3]$ i $[13]$ należy odrzucić ze względu na istotnie słabe dopasowanie ($p < 0,001$).

\newpage

# Część IV i V

## Zadanie 8

Przyjmując model log-liniowy $[123]$ oraz $[12 \: 23]$ dla zmiennych opisanych w zadaniu 7 oszacowano prawdopobiebieństwa:

 -    ze osoba pracująca na stanowisku kierowniczym jest zdecydowanie zadowolona ze
 szkoleń,
 
 -    ze osoba o `STAZu` pracy krótszym niż rok pracuje na stanowisku kierowniczym;
 
 -    ze osoba o `STAZu` pracy powyżej trzech lat nie pracuje na stanowisku kierowniczym.



```{r, echo=FALSE,results='hide'}

dane <- read.csv("ankieta.csv", sep = ";", fileEncoding = "Latin2")
colnames(dane) <- c('DZIAŁ','STAZ','CZY_KIER', 'PYT_1', 'PYT_2', 'PYT_3', 'PLEC', 'WIEK')


dane$CZY_KIER <- factor(dane$CZY_KIER, levels = c("Nie", "Tak"))
dane$PYT_2    <- factor(dane$PYT_2, levels = as.character(-2:2))
dane$STAZ     <- factor(dane$STAZ, levels = c("1", "2", "3"))

#tabela kontyngencji
tab<- xtabs(~ CZY_KIER + PYT_2 + STAZ, data = dane, drop.unused.levels = FALSE)

total <- sum(tab)

#Model 123
model_123 <- loglm(~ CZY_KIER * PYT_2 * STAZ, data = tab)
p_123 <- fitted(model_123) / total

#Model [12 23]
model_1223 <- loglm(~ CZY_KIER * PYT_2 + PYT_2 * STAZ, data = tab)
p_1223 <- fitted(model_1223) / total

# ---- Prawdopodobieństwo 1 ----

emp1 <- sum(tab["Tak", "2", ]) / total
mod1_123 <- sum(p_123["Tak", "2", ])
mod1_1223 <- sum(p_1223["Tak", "2", ])

# ---- Prawdopodobieństwo 2 ----

emp2 <- sum(tab["Tak", , "1"]) / sum(tab[, , "1"])
mod2_123 <- sum(p_123["Tak", , "1"]) / sum(p_123[, , "1"])
mod2_1223 <- sum(p_1223["Tak", , "1"]) / sum(p_1223[, , "1"])

# ---- Prawdopodobieństwo 3 ----

emp3 <- sum(tab["Nie", , "3"]) / sum(tab[, , "3"])
mod3_123 <- sum(p_123["Nie", , "3"]) / sum(p_123[, , "3"])
mod3_1223 <- sum(p_1223["Nie", , "3"]) / sum(p_1223[, , "3"])


```

\begin{table}[H]
\centering
\caption{Porównanie estymowanych prawdopodobieństw dla modeli log-liniowych}
\begin{tabular}{lccc}
\toprule
Opis prawdopodobieństwa & Dane & Model [123] & Model [12 23] \\
\midrule
1. Kierownik zdecydowanie zadowolony ze szkoleń & 0.4815 & 0.4815 & 0.4815 \\
2. Osoba o STAZu krótszym niż rok jest kierownikiem & 0.0244 & 0.0244 & 0.1281 \\
3. Osoba o STAZu dłuższym niż 3 lata nie jest kierownikiem & 0.5263 & 0.5263 & 0.7781 \\
\bottomrule
\end{tabular}
\end{table}


Wszystkie trzy modele - dane empiryczne, model pełny $[123]$ i uproszczony $[12 \: 23]$ - zgodnie wskazują, że osoby na stanowiskach kierowniczych są często zdecydowanie zadowolone ze szkoleń.

W przypadku modelu $[12 \: 23]$ znacznie przeszacowano prawdopodobieństwo, że osoba o STAZu krótszym niż rok jest kierownikiem, co świadczy o braku pełnej interakcji z czasem pracy.

Model $[12 \: 23]$ również znacząco zawyżył szansę, że osoba z długim `STAZem` nie pełni funkcji kierowniczej, co może świadczyć o jego niedopasowaniu względem rzeczywistego układu zależności między zmiennymi.

\newpage

## Zadanie 9

Dla danych wskazanych w zadaniu 7 zweryfikowano następujące hipotezy:

-   zmienne losowe CZY_KIER, PYT_2 i STAZ sa wzajemnie niezależne;

-   zmienna losowa PYT_2 jest niezależna od pary zmiennych CZY_KIER i STAZ;

-   zmienna losowa PYT_2 jest niezależna od zmiennej CZY_KIER, przy ustalonej
 wartości zmiennej STAZ



```{r,echo=FALSE, results='hide'}
df <- read.csv("ankieta.csv", sep = ";", fileEncoding = "Latin2")
colnames(df) <- c('DZIAŁ','STAZ','CZY_KIER', 'PYT_1', 
                    'PYT_2', 'PYT_3', 'PŁEĆ', 'WIEK')

dane <- df
char_col <- sapply(df, is.character)
df[ ,char_col] <- lapply(df[ ,char_col], as.factor)
sum = sum(is.na(df))

if (sum != 0){na_coords <- which(is.na(df), arr.ind = TRUE)
apply(na_coords, 1, function(x) paste0("(", x[1], ", ", x[2], ")"))}

roundandformat <- function(x, d) {
  formatC(x, format = "f", digits = d)
}

tab_8 <- data.frame(ftable(dane$CZY_KIER, dane$PYT_2, dane$STAZ))
colnames(tab_8) <- c("CZY_KIER", "PYT_2", "STAZ", "Freq")


anova_nadmodel <- function(mi_0, mi_1s) {
  p <- list()
  for (i in seq_along(mi_1s)) {
    x <- anova(mi_0, mi_1s[[i]], test = "Chisq")
    p[[i]] <- 1 - pchisq(x$Deviance[2], x$Df[2])
  }
  names(p) <- names(mi_1s)
  return(p)
}
colnames(tab_8)

```

```{r, echo=FALSE,results='hide'}
model_1_2_3 = glm(Freq ~ CZY_KIER + PYT_2 + STAZ, data = tab_8, family = poisson)

models <- list(
  model_12 = glm(Freq ~ CZY_KIER * PYT_2 + STAZ, data = tab_8, family = poisson),
  model_13 = glm(Freq ~ CZY_KIER * STAZ + PYT_2, data = tab_8, family = poisson),
  model_23 = glm(Freq ~ PYT_2 * STAZ + CZY_KIER, data = tab_8, family = poisson),
  model_12_13 = glm(Freq ~ CZY_KIER * PYT_2 + CZY_KIER * STAZ + PYT_2 + STAZ, data = tab_8, family = poisson),
  model_12_23 = glm(Freq ~ CZY_KIER * PYT_2 + PYT_2 * STAZ + CZY_KIER + STAZ, data = tab_8, family = poisson),
  model_13_23 = glm(Freq ~ CZY_KIER * STAZ + PYT_2 * STAZ + CZY_KIER + PYT_2, data = tab_8, family = poisson),
  model_12_13_23 = glm(Freq ~ CZY_KIER * PYT_2 + CZY_KIER * STAZ + PYT_2 * STAZ , data = tab_8, family = poisson),
  model_123 = glm(Freq ~ CZY_KIER * PYT_2 * STAZ, data = tab_8, family = poisson)
)

anova_nadmodel(model_1_2_3, models)

```
  
  a) **$H_0:$** Wszystkie trzy zmienne są wzajemnie niezależne - $[1 \: 2 \: 3]$

**Model bazowy**: model $[1 \: 2 \: 3]$
**Modele pełniejsze (4 nadmodele)**:


\begin{table}[H]
\centering
\caption{Porównanie modeli dla hipotezy $H_0$ — niezależność trójkowa}
\label{tab:hip_a}
\begin{tabular}{lrrr}
\toprule
Model        &  \textit{p}-value \\
\midrule
{[12 13]}       &  0.0016 \\
{[12 23]}       &  4.73e-05 \\
{[13 23]}       & 9.87e-06 \\
{[12 13 23]}    & 2.77e-05 \\
\bottomrule
\end{tabular}
\end{table}

Wszystkie nadmodele istotnie poprawiają dopasowanie w porównaniu do modelu zakładającego pełną niezależność.
Odrzucamy hipotezę trójkowej niezależności — zmienne `CZY_KIER`, `PYT_2` i `STAŻ` nie są wzajemnie niezależne.
```{r, echo=FALSE,results='hide'}
model_13 = glm(Freq ~ CZY_KIER * STAZ + PYT_2, family = poisson, data = tab_8)

models <- list(
  model_12_13 = glm(Freq ~ CZY_KIER * PYT_2 + CZY_KIER * STAZ, data = tab_8, family = poisson),
  model_13_23 = glm(Freq ~ CZY_KIER * STAZ + PYT_2 * STAZ, data = tab_8, family = poisson),
  model_12_13_23 = glm(Freq ~ CZY_KIER * STAZ + PYT_2*STAZ + CZY_KIER*PYT_2, family = poisson, data = tab_8),
  model_123 = glm(Freq ~ CZY_KIER * PYT_2 * STAZ, data = tab_8, family = poisson)
)

anova_nadmodel(model_13, models)
```
 
  b) **$H_0:$** Zmienna `PYT_2` jest niezależna od `CZY_KIER` i `STAZ` - $[2 \: 13]$

**Model bazowy**: model $[2 \: 13]$
**Modele pełniejsze (4 nadmodele)**:

\begin{table}[H]
\centering
\caption{Porównanie modeli dla hipotezy $H_0$}
\label{tab:hip_b}
\begin{tabular}{lrrr}
\toprule
Model     & \textit{p}-value \\
\midrule
{[12 13]}  & 0.0397 \\
{[13 23]}  & 0.0056 \\
{[12 13 23]}  & 0.0104 \\
{[123]}   & 0.0810 \\
\bottomrule
\end{tabular}
\end{table}

Dla trzech z czterech nadmodeli $p-value < 0.05$, co oznacza, że wprowadzenie zależności `PYT_2` z pozostałymi zmiennymi istotnie poprawia dopasowanie modelu.
Odrzucamy hipotezę, że `PYT_2` jest niezależna od (`CZY_KIER`, `STAŻ`).
```{r, echo=FALSE,results='hide'}
  model_13_23 = glm(Freq ~ CZY_KIER * STAZ + PYT_2 * STAZ, data = tab_8, family = poisson)
  
models <- list(
  model_12_13_23 = glm(Freq ~ CZY_KIER * STAZ + PYT_2*STAZ + CZY_KIER*PYT_2, family = poisson, data = tab_8),
  model_123 = glm(Freq ~ CZY_KIER * PYT_2 * STAZ, data = tab_8, family = poisson)
)

anova_nadmodel(model_13_23, models)
```


  c) $H_0:$ Zmienne `PYT_2` i `CZY_KIER` są nie są bezpośrednio zależne `STAZ` - $[13 \: 23]$

**Model bazowy**: model $[13 \: 23]$

**Modele pełniejsze (1 nadmodel)**:

\begin{table}[H]
\centering
\caption{Porównanie modeli dla hipotezy $H_0$}
\label{tab:hip_c}
\begin{tabular}{lrrr}
\toprule
Model    &  \textit{p}-value \\
\midrule
{[12 13 23]}  & 0.3500 \\
{[123]}  & 0.8446 \\
\bottomrule
\end{tabular}
\end{table}

Obie wartości $p$ są zdecydowanie większe niż $0.05$ – brak podstaw do odrzucenia hipotezy.
Nie odrzucamy hipotezy warunkowej niezależności — `PYT_2` jest niezależna od `CZY_KIER` przy ustalonej wartości `STAŻ`.
